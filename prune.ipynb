{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86942619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55bbc6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = '/workspace/mnt/logs/lily2022-10-30T23-05-28_lily/checkpoints/last.ckpt'\n",
    "#fn = f\"{os.path.splitext(p)[0]}-pruned.ckpt\" if not keep_only_ema else f\"{os.path.splitext(p)[0]}-ema-pruned.ckpt\"\n",
    "fn = '/workspace/mnt/models/pontcha-pruned.ckpt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "371a6502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prunin' in path: /workspace/mnt/logs/pontch2022-10-30T19-51-36_pontch/checkpoints/last.ckpt\n",
      "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers'])\n",
      "removing optimizer states for path /workspace/mnt/logs/pontch2022-10-30T19-51-36_pontch/checkpoints/last.ckpt\n",
      "This is global step 1000.\n",
      "saving pruned checkpoint at: /workspace/mnt/models/pontcha-pruned.ckpt\n",
      "New ckpt size: 4.27 GB. Saved 7.86 GB by removing optimizer states\n"
     ]
    }
   ],
   "source": [
    "keep_only_ema=False\n",
    "print(f\"prunin' in path: {p}\")\n",
    "size_initial = os.path.getsize(p)\n",
    "nsd = dict()\n",
    "sd = torch.load(p, map_location=\"cpu\")\n",
    "print(sd.keys())\n",
    "for k in sd.keys():\n",
    "    if k != \"optimizer_states\":\n",
    "        nsd[k] = sd[k]\n",
    "else:\n",
    "    print(f\"removing optimizer states for path {p}\")\n",
    "if \"global_step\" in sd:\n",
    "    print(f\"This is global step {sd['global_step']}.\")\n",
    "if keep_only_ema:\n",
    "    sd = nsd[\"state_dict\"].copy()\n",
    "    # infer ema keys\n",
    "    ema_keys = {k: \"model_ema.\" + k[6:].replace(\".\", \"\") for k in sd.keys() if k.startswith('model.')}\n",
    "    new_sd = dict()\n",
    "\n",
    "    for k in sd:\n",
    "        if k in ema_keys:\n",
    "            print(k, ema_keys[k])\n",
    "            new_sd[k] = sd[ema_keys[k]]\n",
    "        elif not k.startswith(\"model_ema.\") or k in [\"model_ema.num_updates\", \"model_ema.decay\"]:\n",
    "            new_sd[k] = sd[k]\n",
    "\n",
    "    assert len(new_sd) == len(sd) - len(ema_keys)\n",
    "    nsd[\"state_dict\"] = new_sd\n",
    "else:\n",
    "    sd = nsd['state_dict'].copy()\n",
    "    new_sd = dict()\n",
    "    for k in sd:\n",
    "        new_sd[k] = sd[k]\n",
    "    nsd['state_dict'] = new_sd\n",
    "\n",
    "print(f\"saving pruned checkpoint at: {fn}\")\n",
    "torch.save(nsd, fn)\n",
    "newsize = os.path.getsize(fn)\n",
    "MSG = f\"New ckpt size: {newsize*1e-9:.2f} GB. \" + \\\n",
    "      f\"Saved {(size_initial - newsize)*1e-9:.2f} GB by removing optimizer states\"\n",
    "if keep_only_ema:\n",
    "    MSG += \" and non-EMA weights\"\n",
    "print(MSG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a7ba85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
