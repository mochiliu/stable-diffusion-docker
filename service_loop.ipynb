{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ccc0af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from gsheets import sheet_to_dataframe, dataframe_to_sheet, get_last_updated_time\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "from apiclient.http import MediaFileUpload\n",
    "import mimetypes\n",
    "import subprocess\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import timedelta, datetime, date\n",
    "import pytz\n",
    "import time\n",
    "import papermill as pm\n",
    "import sendgrid\n",
    "from sendgrid.helpers.mail import *\n",
    "\n",
    "\n",
    "ROOT_FOLDER = '1mh-hDd6bGgdcw1oxRcnPNcNrGJvgaHfi' #shared folder on my personal space\n",
    "JOBS_SHEET = '18fVqjzsQx3twrO6j688p-S3BCtkUqgOAURQUcKBjK-g'\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "KERNEL_NAME = 'python3'\n",
    "LOG_TIME_FORMATTING = '%Y-%m-%d %H:%M:%S %Z'\n",
    "PROTECTED_FILES = ['service_loop.ipynb','stable_diffusion_animate_youtube.ipynb','stable_diffusion_animate_youtube_papermill.ipynb','requirements.txt']\n",
    "UPLOAD_EXTENSIONS = ['.mp4','.txt']\n",
    "DELETE_EXTENSIONS = ['.mp4','.txt']\n",
    "CORE_COLUMNS = ['Timestamp', 'YouTube_URL', 'model_name', 'constant_text', 'email']\n",
    "LOOP_TIME_S = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48291da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "gservice_credentials = json.load(open('/workspace/mnt/private/stablediffusion-364601-d8d8ab40fcd5.json'))\n",
    "creds = service_account.Credentials.from_service_account_info(\n",
    "        gservice_credentials, scopes=SCOPES)\n",
    "%env GOOGLE_SERVICE_ACCT_JSON={json.dumps(gservice_credentials)}\n",
    "\n",
    "send_grid = json.load(open('/workspace/mnt/private/sendgrid.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "080ca171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mochiliu@gmail.com'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6601a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a11f1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_timestamps = []\n",
    "status_messages = []\n",
    "def update_status(status_message, write_to_sheet=True):\n",
    "    #updates the status sheet\n",
    "    status_timestamp = datetime.now(pytz.utc).strftime(LOG_TIME_FORMATTING)\n",
    "    print(f'{status_timestamp}: {status_message}')\n",
    "    if len(status_messages)>0 and status_messages[-1].startswith('checking'):\n",
    "        # the last update was a check operation, pop the last items\n",
    "        status_timestamps.pop()\n",
    "        status_messages.pop()    \n",
    "    status_timestamps.append(status_timestamp)\n",
    "    status_messages.append(status_message)\n",
    "    df_status = pd.DataFrame({'time': status_timestamps,'message':status_messages}) \n",
    "    if write_to_sheet:\n",
    "        dataframe_to_sheet(df_status, JOBS_SHEET, 'Status')\n",
    "        \n",
    "def create_folder_gdrive(service, folder_name, parent_folder_id):\n",
    "    #make a new folder on google drive\n",
    "    file_metadata = {\n",
    "        'name': folder_name,\n",
    "        'mimeType': 'application/vnd.google-apps.folder',\n",
    "        'parents': [parent_folder_id]\n",
    "    }\n",
    "    file = service.files().create(body=file_metadata,\n",
    "                                        fields='id').execute()\n",
    "    new_folder_id = file.get('id')\n",
    "    return new_folder_id\n",
    "\n",
    "def upload_file_gdrive(service, file_name, parent_folder_id):\n",
    "    #make a new pdf file \n",
    "    file_metadata = {\n",
    "        'name': file_name,\n",
    "        'parents': [parent_folder_id]\n",
    "    }\n",
    "    mimetype = mimetypes.MimeTypes().guess_type(file_name)[0]\n",
    "    media = MediaFileUpload(file_name,\n",
    "                            mimetype=mimetype,\n",
    "                            resumable=True)\n",
    "    file = service.files().create(body=file_metadata,\n",
    "                                        media_body=media,\n",
    "                                        fields='id').execute()\n",
    "    output_file_id = file.get('id')\n",
    "    return output_file_id\n",
    "\n",
    "def scan_for_files(extensions:list)->list:\n",
    "    '''selects files with the extensions from the current directory'''\n",
    "    files_with_extensions = []\n",
    "    for file in os.listdir(\"./\"):\n",
    "        for extension in extensions:\n",
    "            if file.endswith(extension):\n",
    "                files_with_extensions.append(file)\n",
    "    return files_with_extensions\n",
    "\n",
    "def remove_files(files):\n",
    "    for file in files:\n",
    "        if not file in PROTECTED_FILES:\n",
    "            os.remove(file)\n",
    "            print(f'deleting {file}')\n",
    "            \n",
    "            \n",
    "def send_email(to_email, link, title):\n",
    "    if not \"@\" in to_email:\n",
    "        return\n",
    "    try:\n",
    "        sg = sendgrid.SendGridAPIClient(api_key=send_grid['api_key'])\n",
    "        from_email = Email(send_grid['from_email'])\n",
    "        to_email = To(to_email)\n",
    "        subject = f\"your rendering of {title} is ready\"\n",
    "        content = Content(\"text/plain\", link)\n",
    "        mail = Mail(from_email, to_email, subject, content)\n",
    "        response = sg.client.mail.send.post(request_body=mail.get())\n",
    "        print(response.status_code)\n",
    "        print(response.body)\n",
    "        print(response.headers)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff79386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-10 02:39:03 UTC: checking for new jobs\n",
      "2022-10-10 02:39:05 UTC: started job https://www.youtube.com/watch?v=Dtywt38RnX4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Black is not installed, parameters wont be formatted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting Lakes_of_Pontchartrain_20221010_020734.mp4\n",
      "deleting 20221010020734_settings.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e874285ec8874d8a85b034cba0d86513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Executing'), FloatProgress(value=0.0, max=26.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "while True: # loop forever\n",
    "    try:\n",
    "        loop_start_time = time.time()\n",
    "        #check the gsheet if it has been edited in the last LOOPTIME seconds\n",
    "        #allow the user to keep editing without starting any jobs\n",
    "        time_since_last_update = datetime.now(pytz.utc) - get_last_updated_time(JOBS_SHEET)\n",
    "\n",
    "        update_status(f'checking for new jobs')\n",
    "\n",
    "        #check the gsheet for jobs\n",
    "        df_todo_orig = sheet_to_dataframe(JOBS_SHEET, 'ToDo')\n",
    "        df_completed_orig = sheet_to_dataframe(JOBS_SHEET, 'Completed')\n",
    "\n",
    "        df_todo_orig = df_todo_orig[df_todo_orig['YouTube_URL'].str.strip().astype(bool)]\n",
    "        # drop duplicated timestamps so that it is unique\n",
    "        df_todo_orig = df_todo_orig.set_index('Timestamp', drop=True)\n",
    "        df_todo_orig = df_todo_orig[~df_todo_orig.index.duplicated(keep='first')]\n",
    "        df_todo_orig = df_todo_orig.reset_index()\n",
    "        #determine which items are still todo using the timestamps as key\n",
    "        todo_timestamps = set(df_todo_orig.get('Timestamp',[])).difference(set(df_completed_orig.get('Timestamp',[])))\n",
    "        df_todo = df_todo_orig.loc[df_todo_orig['Timestamp'].isin(todo_timestamps)]\n",
    "\n",
    "        created_at_timestamps = []\n",
    "        gdrive_link = []\n",
    "        titles = []\n",
    "        for idx, job_row in df_todo.iterrows():\n",
    "            # loop over the videos to make, run papermill\n",
    "            try:\n",
    "                timestamp_str = datetime.now(pytz.utc).strftime(LOG_TIME_FORMATTING)\n",
    "                created_at_timestamps.append(timestamp_str)\n",
    "\n",
    "                output_file = job_row.YouTube_URL.split('=')[-1]\n",
    "                output_file_ipynb = 'out.ipynb'\n",
    "                update_status(f'started job {job_row.YouTube_URL}')\n",
    "                #clean working directory\n",
    "                remove_files(scan_for_files(DELETE_EXTENSIONS))\n",
    "\n",
    "                #use papermill to run the analysis\n",
    "                nb = pm.execute_notebook(\n",
    "                   'stable_diffusion_animate_youtube_papermill.ipynb',\n",
    "                    output_file_ipynb,\n",
    "                    kernel_name=KERNEL_NAME,\n",
    "                    parameters=dict(YOUTUBE_URL=job_row.YouTube_URL, \n",
    "                                    MODEL_NAME = job_row.model_name,\n",
    "                                    CONSTANT_TEXT=\" \" + job_row.constant_text,)\n",
    "                )\n",
    "                \n",
    "                try:\n",
    "                    with open('title') as f:\n",
    "                        output_file = f.read() #replace file with the title of the music video if available\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "\n",
    "                #set up gdrive folder\n",
    "                service = build('drive', 'v3', credentials=creds)\n",
    "                new_folder_id = create_folder_gdrive(service, output_file, ROOT_FOLDER)\n",
    "\n",
    "                #scrape for other relevant files in local directory like\n",
    "                #contact sheet and animation videos\n",
    "                files_to_upload = scan_for_files(UPLOAD_EXTENSIONS)\n",
    "                file_ids = []\n",
    "                for file_to_upload in files_to_upload:\n",
    "                    if not file_to_upload in PROTECTED_FILES:\n",
    "                        file_ids.append(upload_file_gdrive(service, file_to_upload, new_folder_id))\n",
    "                \n",
    "                link = f'https://drive.google.com/drive/folders/{new_folder_id}'\n",
    "                #send notification email\n",
    "                send_email(job_row.email, link, output_file)\n",
    "                \n",
    "                #log\n",
    "                gdrive_link.append(link)\n",
    "                titles.append(output_file)\n",
    "                status_txt = f'finshed job {output_file}'\n",
    "            except Exception as e:\n",
    "                gdrive_link.append(str(e))\n",
    "                status_txt = str(e)\n",
    "                titles.append('')\n",
    "            update_status(status_txt)\n",
    "\n",
    "        #update the completed sheet\n",
    "        df_just_finished = df_todo.copy()\n",
    "        df_just_finished['created_at'] = created_at_timestamps\n",
    "        df_just_finished['link'] = gdrive_link\n",
    "        df_just_finished['title'] = titles\n",
    "\n",
    "        df_completed = pd.concat([df_just_finished,df_completed_orig])\n",
    "        dataframe_to_sheet(df_completed, JOBS_SHEET, 'Completed')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    sleep_time = LOOP_TIME_S - (time.time() - loop_start_time)\n",
    "    if sleep_time > 0:\n",
    "        time.sleep(sleep_time)       # sleep accordingly so the full iteration takes a fixed time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
